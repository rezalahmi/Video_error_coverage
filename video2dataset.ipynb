{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "JKDjkGltqzSi",
    "outputId": "255449b7-e332-4057-f8bc-92b5698a9252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "id": "ljfNCCOWZ9sO",
    "outputId": "04e2c05d-8353-4600-d9ef-d91640f1589a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```text\n",
      "=== Software === \n",
      "python        : 3.6.9\n",
      "fastai        : 1.0.60\n",
      "fastprogress  : 0.2.2\n",
      "torch         : 1.3.1\n",
      "nvidia driver : 418.67\n",
      "torch cuda    : 10.1.243 / is available\n",
      "torch cudnn   : 7603 / is enabled\n",
      "\n",
      "=== Hardware === \n",
      "nvidia gpus   : 1\n",
      "torch devices : 1\n",
      "  - gpu0      : 15079MB | Tesla T4\n",
      "\n",
      "=== Environment === \n",
      "platform      : Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic\n",
      "distro        : #1 SMP Thu Aug 8 02:47:02 PDT 2019\n",
      "conda env     : Unknown\n",
      "python        : /usr/bin/python3\n",
      "sys.path      : \n",
      "/env/python\n",
      "/usr/lib/python36.zip\n",
      "/usr/lib/python3.6\n",
      "/usr/lib/python3.6/lib-dynload\n",
      "/usr/local/lib/python3.6/dist-packages\n",
      "/usr/lib/python3/dist-packages\n",
      "/usr/local/lib/python3.6/dist-packages/IPython/extensions\n",
      "/root/.ipython\n",
      "```\n",
      "\n",
      "Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\n",
      "\n",
      "Optional package(s) to enhance the diagnostics can be installed with:\n",
      "pip install distro\n",
      "Once installed, re-run this utility to get the additional information\n"
     ]
    }
   ],
   "source": [
    "from fastai.utils.show_install import *\n",
    "show_install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fs8hJ8tstIik"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8GumC3avtar3"
   },
   "outputs": [],
   "source": [
    "def optflow_gen(video_dir, normalize = True):\n",
    "  # The video feed is read in as a VideoCapture object\n",
    "  cap =  cv.VideoCapture(video_dir)\n",
    "\n",
    "  data_name = (video_dir.split(\"/\")[-1]).split(\".\")[0]\n",
    "\n",
    "  number_of_frame = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "  # ret = a boolean return value from getting the frame, first_frame = the first frame in the entire video sequence\n",
    "  ret, first_frame = cap.read()\n",
    "\n",
    "  # Converts frame to grayscale because we only need the luminance channel for detecting edges - less computationally expensive\n",
    "  prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "  # Creates an frame filled with zero intensities with the same dimensions as the frame\n",
    "  data_x_axis = np.zeros((first_frame.shape[0], first_frame.shape[1], number_of_frame))\n",
    "  data_y_axis = np.zeros((first_frame.shape[0], first_frame.shape[1], number_of_frame))\n",
    "  frame_num = 0\n",
    "\n",
    "  while(cap.isOpened()):\n",
    "    frame_num += 1\n",
    "    # ret = a boolean return value from getting the frame, frame = the current frame being projected in the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Converts each frame to grayscale. Except part will active when all frames of video feed into network and input of cv.cvtColor will be empty\n",
    "    try:\n",
    "      gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    except :\n",
    "      break\n",
    "\n",
    "    # Calculates dense optical flow by Farneback method\n",
    "    # https://docs.opencv.org/3.0-beta/modules/video/doc/motion_analysis_and_object_tracking.html#calcopticalflowfarneback\n",
    "    flow = cv.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    # Normalization\n",
    "    if normalize == True:\n",
    "        flow_min = flow.min(axis=(0, 1), keepdims=True)\n",
    "        flow_max = flow.max(axis=(0, 1), keepdims=True)\n",
    "        flow = (flow - flow_min)/(flow_max-flow_min)\n",
    "    \n",
    "    data_x_axis[:,:,frame_num] = flow[:,:,0]\n",
    "    data_y_axis[:,:,frame_num] = flow[:,:,1]\n",
    "\n",
    "    # Updates previous frame\n",
    "    prev_gray = gray\n",
    "    # Frames are read by intervals of 1 millisecond. The programs breaks out of the while loop when the user presses the 'q' key\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "  # The following frees up resources and closes all windows\n",
    "  cap.release()\n",
    "  cv.destroyAllWindows()\n",
    "  # We wil remove first frame because it is all zero\n",
    "  return data_x_axis[...,1:], data_y_axis[...,1:], data_name\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJIU8Fpkx2iq"
   },
   "outputs": [],
   "source": [
    "def dataset_generate(raw_data, num_frames_seq = 3, step_of_move_along_height = 16, data_width = 48):\n",
    "  # raw_data: A numpy ndarray resulted from optflow_gen(video_dir)\n",
    "  # num_frames_seq: It shows that how many frames you want to predict next frame\n",
    "  # step_of_move_along_height: In generating dataset, the step of move along height of each frame\n",
    "  # data_width: Width of each sample of dataset \n",
    "\n",
    "  dataset_X = []\n",
    "  label_X = []\n",
    "\n",
    "  for j in range(num_frames_seq,raw_data.shape[2]):\n",
    "      for i in range(0, raw_data.shape[0]-data_width+1, step_of_move_along_height):\n",
    "         b = range(i, i+data_width)\n",
    "         X_input = np.zeros((data_width,raw_data.shape[1],num_frames_seq))\n",
    "         X_label = np.zeros((data_width,raw_data.shape[1],1))\n",
    "        \n",
    "         for t in range(num_frames_seq):\n",
    "           X_input [...,t] = raw_data[b,:,j+t-num_frames_seq]\n",
    "         X_label = raw_data[b,...,j]\n",
    "        \n",
    "         dataset_X.append(X_input)\n",
    "         label_X.append (X_label)\n",
    "\n",
    "  dataset_X = np.asarray(dataset_X, dtype=np.float64)\n",
    "  label_X = np.asarray(label_X, dtype=np.float64)\n",
    "  \n",
    "  # First frame that was all zeros removed in optflow_gen section\n",
    "  #dataset_X = dataset_X[16:,...] \n",
    "  # prepration resize for convlstm\n",
    "  dataset_X = np.transpose(np.expand_dims((dataset_X), axis =1), (0, 4, 2, 3, 1))\n",
    "\n",
    "  #label_X = label_X[16:,...]\n",
    "  label_X= np.expand_dims(label_X, axis =-1)\n",
    "\n",
    "  return dataset_X, label_X\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUm7MLl0hNSm"
   },
   "outputs": [],
   "source": [
    "def save_dataset(dataset, label, save_dir, data_name):\n",
    "   # dataset_X: First ret of optflow_gen(video_dir)\n",
    "   # label_X: Second ret of optflow_gen(video_dir)\n",
    "   # save_dir: Direction for saving dataset\n",
    "   # data_name: Third ret of optflow_gen(video_dir)\n",
    "   \n",
    "   dataset = np.split(dataset, len(dataset), axis=0)\n",
    "   label = np.split(label, len(label), axis=0)\n",
    "  \n",
    "   for j in range(len(dataset)):\n",
    "     temp_dataset = dataset[j]\n",
    "     temp_label = label[j]\n",
    "\n",
    "     np.save(save_dir + \"/dataset_\" + data_name + str(j), temp_dataset)\n",
    "     np.save(save_dir + \"/label_\" + data_name + str(j), temp_label)\n",
    "\n",
    "     print(\"created \" + data_name + str(j))\n",
    "\n",
    "   print(\"Creating dataset from \" + str(data_name) + \" video is done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRZnAgCmyDbf"
   },
   "outputs": [],
   "source": [
    "def normalizer(data_dir):    \n",
    "    # data_dir: Direction of  dataset\n",
    "    \n",
    "    flow = sorted(glob.glob(data_dir + \"/dataset\" + \"*\" + \".npy\"))\n",
    "    label = sorted(glob.glob(data_dir + \"/label\" + \"*\" + \".npy\"))\n",
    "\n",
    "    for i in flow:\n",
    "      dataset_X = np.load(i)\n",
    "      dataset_X_min = dataset_X.min(axis=(2, 3), keepdims=True)\n",
    "      dataset_X_max = dataset_X.max(axis=(2, 3), keepdims=True)\n",
    "      dataset_X_norm = (dataset_X - dataset_X_min)/(dataset_X_max-dataset_X_min)\n",
    "      np.save(i, dataset_X_norm)\n",
    "      del dataset_X, dataset_X_min, dataset_X_max, dataset_X_norm\n",
    "\n",
    "    for j in label:\n",
    "      label_X = np.load(j)\n",
    "      label_X_min = label_X.min(axis=(1, 2), keepdims=True)\n",
    "      label_X_max = label_X.max(axis=(1, 2), keepdims=True)\n",
    "      label_X_norm = (label_X - label_X_min)/(label_X_max-label_X_min)\n",
    "      np.save(j, label_X_norm)\n",
    "      del label_X, label_X_min, label_X_max, label_X_norm\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlncWEu5jAlK"
   },
   "outputs": [],
   "source": [
    "video_dir = \"/content/drive/My Drive/Videos/bus.y4m\"\n",
    "save_dir_X = \"/content/drive/My Drive/temporary_X\"\n",
    "#save_dir_Y = \"/content/drive/My Drive/temporary_Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OoVkXuuXyB5b"
   },
   "outputs": [],
   "source": [
    "data_x, _, data_name = optflow_gen(video_dir)\n",
    "#data_x, data_y, data_name = optflow_gen(video_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VlQXHYO1ymqW"
   },
   "outputs": [],
   "source": [
    "dataset_X, label_X = dataset_generate(data_x)\n",
    "#dataset_Y, label_Y = dataset_generate(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3psAmbLe1wX"
   },
   "outputs": [],
   "source": [
    "save_dataset(dataset_X, label_X, save_dir_X, data_name)\n",
    "#save_dataset(dataset_Y, label_Y, save_dir_Y, data_name)\n",
    "del data_x, data_name, dataset_X, label_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlwlJCbghr1d"
   },
   "outputs": [],
   "source": [
    "# normalizer(save_dir_X)\n",
    "# normalizer(save_dir_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEtN0UDQkEjh"
   },
   "outputs": [],
   "source": [
    "video_dir = \"/content/drive/My Drive/Videos/akiyo.y4m\"\n",
    "data_x, _, data_name = optflow_gen(video_dir)\n",
    "dataset_X, label_X = dataset_generate(data_x)\n",
    "save_dataset(dataset_X, label_X, save_dir_X, data_name)\n",
    "del data_x, data_name, dataset_X, label_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dn8UZkO7kuQE"
   },
   "outputs": [],
   "source": [
    "video_dir = \"/content/drive/My Drive/Videos/foreman.y4m\"\n",
    "data_x, _, data_name = optflow_gen(video_dir)\n",
    "dataset_X, label_X = dataset_generate(data_x)\n",
    "save_dataset(dataset_X, label_X, save_dir_X, data_name)\n",
    "del data_x, data_name, dataset_X, label_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4vdosJbjoPH"
   },
   "outputs": [],
   "source": [
    "video_dir = \"/content/drive/My Drive/Videos/coastguard.y4m\"\n",
    "data_x, _, data_name = optflow_gen(video_dir)\n",
    "dataset_X, label_X = dataset_generate(data_x)\n",
    "save_dataset(dataset_X, label_X, save_dir_X, data_name)\n",
    "del data_x, data_name, dataset_X, label_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yi2Rh3Vnr6bD"
   },
   "outputs": [],
   "source": [
    "video_dir = \"/content/drive/My Drive/Videos/container.y4m\"\n",
    "data_x, _, data_name = optflow_gen(video_dir)\n",
    "dataset_X, label_X = dataset_generate(data_x)\n",
    "save_dataset(dataset_X, label_X, save_dir_X, data_name)\n",
    "del data_x, data_name, dataset_X, label_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_JbQDdBG-Ne"
   },
   "outputs": [],
   "source": [
    "video_dir = \"/content/drive/My Drive/Videos/hall_monitor.y4m\"\n",
    "data_x, _, data_name = optflow_gen(video_dir)\n",
    "dataset_X, label_X = dataset_generate(data_x)\n",
    "save_dataset(dataset_X, label_X, save_dir_X, data_name)\n",
    "del data_x, data_name, dataset_X, label_X"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "video2dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
